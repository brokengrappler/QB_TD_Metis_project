{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time, os\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom selenium import webdriver\\nfrom selenium.webdriver.common.keys import Keys\\nfrom selenium.webdriver.common.action_chains import ActionChains\\n\\nchromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\\nos.environ[\"webdriver.chrome.driver\"] = chromedriver\\n'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.pro-football-reference.com/players/'\n",
    "\n",
    "#scrape Jared Goff first\n",
    "#player = 'players/G/GoffJa00.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_htm():\n",
    "    '''\n",
    "    Use name to get name for player's html page identifier\n",
    "    return:\n",
    "        dict of {first_part_htm_names : player_name}\n",
    "    '''\n",
    "    qb_list_file = './pfr_scraped/master_qb_list.csv'\n",
    "    qb_df = pd.read_csv(qb_list_file, index_col=0)\n",
    "    htm_name_dict = {}\n",
    "\n",
    "    qb_df = qb_df['0'].str.split(expand=True).copy()\n",
    "    qb_df[2] = qb_df[0] + ' ' + qb_df[1]\n",
    "    qb_df.rename({0:'First', 1:'Last', 2:'Full'}, axis=1, inplace=True)\n",
    "    qb_df['htm_name'] = qb_df['Last'].str.slice(stop=4) + qb_df['First'].str.slice(stop=2)\n",
    "    htm_name_dict = dict(zip(qb_df['htm_name'], qb_df['Full']))\n",
    "    return htm_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MannPe': 'Peyton Manning'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htm_name_dict = get_player_htm()\n",
    "htm_name_dict\n",
    "test_dict = {}\n",
    "test_dict['MannPe'] = 'Peyton Manning'\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(htm_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(htm_dict):\n",
    "    '''\n",
    "    Scrape page and store in a list of soup files\n",
    "    arg:\n",
    "        list of qb's name as html identifier\n",
    "    return:\n",
    "        list of players pages in soup form\n",
    "    '''\n",
    "    ua = UserAgent()\n",
    "    user_agent = {'User-agent' : ua.random}\n",
    "    player_page_soups = []\n",
    "    error_list = []\n",
    "\n",
    "    for qb_htm, qb_name in htm_dict.items():\n",
    "        for x in range(6):\n",
    "            name = qb_htm + '0' + str(x) + '.htm'\n",
    "            add_url = qb_htm[0] + '/' + name\n",
    "            response = requests.get(base_url + add_url, headers=user_agent)\n",
    "            if response.status_code == 200:\n",
    "                print(str(response.status_code) + add_url)\n",
    "                page_soup = BeautifulSoup(response.text, 'lxml')\n",
    "                page_name = page_soup.find('h1',{'itemprop':'name'}).text\n",
    "                if page_name != qb_name:\n",
    "                    time.sleep(random.random() + random.randint(1,4))\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                print('Something\\'s wrong with:' + add_url)\n",
    "                error_list.append(qb_name)\n",
    "                break\n",
    "        player_page_soups.append(page_soup)\n",
    "        time.sleep(random.random() + random.randint(1,4))        \n",
    "    return player_page_soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scrape_page(soup_list):\n",
    "    qb_soup_list = [k.prettify() for k in soup_list]\n",
    "    # add the custom word to standout, I chose BREAKHERE\n",
    "    list_with_breaks = [m+'BREAKHERE' for m in qb_soup_list]\n",
    "    compiled_list = \"\".join(list_with_breaks)\n",
    "    with open('./pfr_scraped/qb_soup_list.txt', 'w') as file:\n",
    "        file.write(compiled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_scrape_page(player_page_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_table(soup_list):\n",
    "    # for each soup (aka players page), return big_table to get_stats and get_headers\n",
    "    big_table = page_soup.find_all('table', {'id':'passing'})\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(table):\n",
    "    stats = defaultdict(list)\n",
    "    stat_table = table[0].find_all('tr', class_='full_table')\n",
    "    for ele in stat_table:\n",
    "        year = ele.find('a').text\n",
    "        temp_stat = ele.find_all('td')\n",
    "        for num in temp_stat:\n",
    "            stats[year].append(num.text)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_stats(big_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(table):\n",
    "    '''\n",
    "    Grab stat headers from player's BS table\n",
    "    arg:\n",
    "        BS object containing players info (from scrape_page)\n",
    "    return:\n",
    "        stat labels in a list\n",
    "    '''\n",
    "    stat_header = []\n",
    "\n",
    "    stat_table = table[0].find_all('tr')\n",
    "    header_soup = stat_table[0].find_all('th')\n",
    "    for header in header_soup:\n",
    "        stat_header.append(header.text)\n",
    "    return stat_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = get_headers(big_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'Goff_test.csv'\n",
    "\n",
    "with open(csv_file, 'w') as csvfile:\n",
    "    csvfile.write(','.join(headers)+'\\n')\n",
    "    for key, value in stats.items():\n",
    "        csvfile.write(key+','+','.join(value)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Pos</th>\n",
       "      <th>No.</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>QBrec</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>...</th>\n",
       "      <th>Rate</th>\n",
       "      <th>QBR</th>\n",
       "      <th>Sk</th>\n",
       "      <th>Yds.1</th>\n",
       "      <th>NY/A</th>\n",
       "      <th>ANY/A</th>\n",
       "      <th>Sk%</th>\n",
       "      <th>4QC</th>\n",
       "      <th>GWD</th>\n",
       "      <th>AV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>22</td>\n",
       "      <td>LAR</td>\n",
       "      <td>qb</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0-7-0</td>\n",
       "      <td>112</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>63.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>26</td>\n",
       "      <td>222</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.82</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>LAR</td>\n",
       "      <td>QB</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>11-4-0</td>\n",
       "      <td>296</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>100.5</td>\n",
       "      <td>52.1</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.72</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>24</td>\n",
       "      <td>LAR</td>\n",
       "      <td>QB</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>13-3-0</td>\n",
       "      <td>364</td>\n",
       "      <td>561</td>\n",
       "      <td>...</td>\n",
       "      <td>101.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>33</td>\n",
       "      <td>223</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.69</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>25</td>\n",
       "      <td>LAR</td>\n",
       "      <td>QB</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9-7-0</td>\n",
       "      <td>394</td>\n",
       "      <td>626</td>\n",
       "      <td>...</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>170</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.46</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Age   Tm Pos  No.   G  GS   QBrec  Cmp  Att  ...   Rate   QBR  Sk  \\\n",
       "0  2016   22  LAR  qb   16   7   7   0-7-0  112  205  ...   63.6  18.9  26   \n",
       "1  2017   23  LAR  QB   16  15  15  11-4-0  296  477  ...  100.5  52.1  25   \n",
       "2  2018   24  LAR  QB   16  16  16  13-3-0  364  561  ...  101.1  63.1  33   \n",
       "3  2019   25  LAR  QB   16  16  16   9-7-0  394  626  ...   86.5   NaN  22   \n",
       "\n",
       "   Yds.1  NY/A  ANY/A   Sk%  4QC  GWD  AV  \n",
       "0    222  3.75   2.82  11.3  NaN  NaN  -2  \n",
       "1    172  7.24   7.72   5.0  1.0  1.0  15  \n",
       "2    223  7.52   7.69   5.6  4.0  4.0  18  \n",
       "3    170  6.90   6.46   3.4  1.0  2.0  12  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Goff_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
