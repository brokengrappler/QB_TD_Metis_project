{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_df = pd.read_pickle(path+'car_avg_stats_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_passer_rating(row):\n",
    "    comp_p = (row['Cmp'] / row['Att'] - .3) * 5\n",
    "    pyd_p = (row['Pass_Yds'] / row['Att'] - 3) * .25\n",
    "    td_p = (row['TD'] / row['Att']) * 20\n",
    "    int_p = 2.375 - (row['Int'] / row['Att']) * 25\n",
    "    return sum([comp_p, pyd_p, td_p, int_p]) / 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(car_avg_df):\n",
    "    '''\n",
    "    Add TD%, Int%, and place QBs in different bins\n",
    "    arg:\n",
    "        DF created from PFR_scrape.py\n",
    "    return:\n",
    "        Two DF: 1) DF with added stats; 2) DF of 2018 QBs who did not play full 2018 season\n",
    "    '''\n",
    "    car_avg_df['YTD_Rating'] = car_avg_df.apply(calc_passer_rating, axis=1)\n",
    "    \n",
    "    car_avg_df['TD%'] = car_avg_df.apply(lambda x: x['TD'] / x['Att'], axis=1)\n",
    "    car_avg_df['Int%'] = car_avg_df.apply(lambda x: x['Int'] / x['Att'], axis=1)\n",
    "    career_ratings = car_avg_df.groupby('name', as_index=False)['YTD_Rating'].mean().reset_index()\n",
    "\n",
    "    # binning QBs by tier\n",
    "    career_ratings['tier'] = pd.qcut(career_ratings['YTD_Rating'], 3, labels=[3, 2, 1])\n",
    "    career_ratings['tier'] = career_ratings['tier'].astype(int)\n",
    "    data_stats = career_ratings.merge(car_avg_df, on='name')\n",
    "    data_stats.rename({'YTD_Rating_x': 'Car Rating', 'YTD_Rating_y': 'YTD_Rating'}, axis=1, inplace=True)\n",
    "\n",
    "    # saving 2018 injured/benched players for inclusion in model\n",
    "    benched_injured_df = data_stats[(data_stats['FY_TD'].isna()) &\n",
    "                                    (data_stats['Year'] == 2018)]\n",
    "    data_stats.dropna(inplace=True)\n",
    "    return data_stats, benched_injured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats, benched_injured_df= add_features(car_avg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>Car Rating</th>\n",
       "      <th>tier</th>\n",
       "      <th>Year</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>Win</th>\n",
       "      <th>TD</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>...</th>\n",
       "      <th>Att/gm</th>\n",
       "      <th>TD/gm</th>\n",
       "      <th>Pass_Yds/gm</th>\n",
       "      <th>Int/gm</th>\n",
       "      <th>Sk/gm</th>\n",
       "      <th>Career W %</th>\n",
       "      <th>Yrs Xp</th>\n",
       "      <th>YTD_Rating</th>\n",
       "      <th>TD%</th>\n",
       "      <th>Int%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrew Luck</td>\n",
       "      <td>0.848839</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>51</td>\n",
       "      <td>156</td>\n",
       "      <td>1838</td>\n",
       "      <td>...</td>\n",
       "      <td>37.936709</td>\n",
       "      <td>1.974684</td>\n",
       "      <td>275.822785</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>2.012658</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>7</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.052052</td>\n",
       "      <td>0.023690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6</td>\n",
       "      <td>Ben Roethlisberger</td>\n",
       "      <td>0.932079</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>216</td>\n",
       "      <td>214</td>\n",
       "      <td>144</td>\n",
       "      <td>363</td>\n",
       "      <td>4616</td>\n",
       "      <td>...</td>\n",
       "      <td>33.185185</td>\n",
       "      <td>1.680556</td>\n",
       "      <td>260.157407</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>2.319444</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>15</td>\n",
       "      <td>0.942487</td>\n",
       "      <td>0.050642</td>\n",
       "      <td>0.026507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8</td>\n",
       "      <td>Blake Bortles</td>\n",
       "      <td>0.780913</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>1561</td>\n",
       "      <td>...</td>\n",
       "      <td>35.093333</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>235.280000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>5</td>\n",
       "      <td>0.806136</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>0.028495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>13</td>\n",
       "      <td>Cam Newton</td>\n",
       "      <td>0.859849</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>68</td>\n",
       "      <td>182</td>\n",
       "      <td>2321</td>\n",
       "      <td>...</td>\n",
       "      <td>31.634146</td>\n",
       "      <td>1.479675</td>\n",
       "      <td>231.455285</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>2.317073</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>8</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>0.027499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>16</td>\n",
       "      <td>Case Keenum</td>\n",
       "      <td>0.936086</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>690</td>\n",
       "      <td>...</td>\n",
       "      <td>34.419355</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>239.903226</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.889195</td>\n",
       "      <td>0.037488</td>\n",
       "      <td>0.020619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>33</td>\n",
       "      <td>Eli Manning</td>\n",
       "      <td>0.814263</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>115</td>\n",
       "      <td>354</td>\n",
       "      <td>4709</td>\n",
       "      <td>...</td>\n",
       "      <td>34.865471</td>\n",
       "      <td>1.587444</td>\n",
       "      <td>246.358744</td>\n",
       "      <td>1.031390</td>\n",
       "      <td>1.762332</td>\n",
       "      <td>0.515695</td>\n",
       "      <td>14</td>\n",
       "      <td>0.848475</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.029582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>54</td>\n",
       "      <td>Josh Rosen</td>\n",
       "      <td>0.667356</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>28.071429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>162.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667356</td>\n",
       "      <td>0.027990</td>\n",
       "      <td>0.035623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>59</td>\n",
       "      <td>Marcus Mariota</td>\n",
       "      <td>0.908043</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>1015</td>\n",
       "      <td>...</td>\n",
       "      <td>28.660714</td>\n",
       "      <td>1.232143</td>\n",
       "      <td>214.357143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.321429</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893731</td>\n",
       "      <td>0.042991</td>\n",
       "      <td>0.026168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>66</td>\n",
       "      <td>Matthew Stafford</td>\n",
       "      <td>0.897102</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>63</td>\n",
       "      <td>218</td>\n",
       "      <td>3114</td>\n",
       "      <td>...</td>\n",
       "      <td>38.531250</td>\n",
       "      <td>1.703125</td>\n",
       "      <td>279.093750</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>2.351562</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>8</td>\n",
       "      <td>0.904890</td>\n",
       "      <td>0.044201</td>\n",
       "      <td>0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>85</td>\n",
       "      <td>Ryan Tannehill</td>\n",
       "      <td>0.829884</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>123</td>\n",
       "      <td>1829</td>\n",
       "      <td>...</td>\n",
       "      <td>33.079545</td>\n",
       "      <td>1.397727</td>\n",
       "      <td>232.204545</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>7</td>\n",
       "      <td>0.870398</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.025764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                name  Car Rating  tier  Year    G   GS  Win   TD  \\\n",
       "21       3         Andrew Luck    0.848839     2  2018   79   79   51  156   \n",
       "45       6  Ben Roethlisberger    0.932079     1  2018  216  214  144  363   \n",
       "51       8       Blake Bortles    0.780913     2  2018   75   73   24  103   \n",
       "81      13          Cam Newton    0.859849     1  2018  123  122   68  182   \n",
       "96      16         Case Keenum    0.936086     1  2018   31   30   17   40   \n",
       "187     33         Eli Manning    0.814263     2  2018  223  223  115  354   \n",
       "281     54          Josh Rosen    0.667356     3  2018   14   13    3   11   \n",
       "310     59      Marcus Mariota    0.908043     1  2018   56   55   27   69   \n",
       "351     66    Matthew Stafford    0.897102     1  2018  128  128   63  218   \n",
       "439     85      Ryan Tannehill    0.829884     2  2018   88   88   42  123   \n",
       "\n",
       "      Cmp  ...     Att/gm     TD/gm  Pass_Yds/gm    Int/gm     Sk/gm  \\\n",
       "21   1838  ...  37.936709  1.974684   275.822785  0.898734  2.012658   \n",
       "45   4616  ...  33.185185  1.680556   260.157407  0.879630  2.319444   \n",
       "51   1561  ...  35.093333  1.373333   235.280000  1.000000  2.600000   \n",
       "81   2321  ...  31.634146  1.479675   231.455285  0.869919  2.317073   \n",
       "96    690  ...  34.419355  1.290323   239.903226  0.709677  1.806452   \n",
       "187  4709  ...  34.865471  1.587444   246.358744  1.031390  1.762332   \n",
       "281   217  ...  28.071429  0.785714   162.714286  1.000000  3.214286   \n",
       "310  1015  ...  28.660714  1.232143   214.357143  0.750000  2.321429   \n",
       "351  3114  ...  38.531250  1.703125   279.093750  0.843750  2.351562   \n",
       "439  1829  ...  33.079545  1.397727   232.204545  0.852273  2.818182   \n",
       "\n",
       "     Career W %  Yrs Xp  YTD_Rating       TD%      Int%  \n",
       "21     0.645570       7    0.909639  0.052052  0.023690  \n",
       "45     0.672897      15    0.942487  0.050642  0.026507  \n",
       "51     0.328767       5    0.806136  0.039134  0.028495  \n",
       "81     0.557377       8    0.864115  0.046775  0.027499  \n",
       "96     0.566667       2    0.889195  0.037488  0.020619  \n",
       "187    0.515695      14    0.848475  0.045531  0.029582  \n",
       "281    0.230769       1    0.667356  0.027990  0.035623  \n",
       "310    0.490909       4    0.893731  0.042991  0.026168  \n",
       "351    0.492188       8    0.904890  0.044201  0.021898  \n",
       "439    0.477273       7    0.870398  0.042254  0.025764  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benched_injured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>Car Rating</th>\n",
       "      <th>tier</th>\n",
       "      <th>Year</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>Win</th>\n",
       "      <th>TD</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>...</th>\n",
       "      <th>Att/gm</th>\n",
       "      <th>TD/gm</th>\n",
       "      <th>Pass_Yds/gm</th>\n",
       "      <th>Int/gm</th>\n",
       "      <th>Sk/gm</th>\n",
       "      <th>Career W %</th>\n",
       "      <th>Yrs Xp</th>\n",
       "      <th>YTD_Rating</th>\n",
       "      <th>TD%</th>\n",
       "      <th>Int%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>1.02425</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>341</td>\n",
       "      <td>...</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>252.375000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937966</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>1.02425</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>691</td>\n",
       "      <td>...</td>\n",
       "      <td>33.656250</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>264.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985395</td>\n",
       "      <td>0.053853</td>\n",
       "      <td>0.018570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>1.02425</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>86</td>\n",
       "      <td>1003</td>\n",
       "      <td>...</td>\n",
       "      <td>33.021277</td>\n",
       "      <td>1.829787</td>\n",
       "      <td>263.702128</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>2.446809</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>0.019974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>1.02425</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>131</td>\n",
       "      <td>1346</td>\n",
       "      <td>...</td>\n",
       "      <td>33.129032</td>\n",
       "      <td>2.112903</td>\n",
       "      <td>274.790323</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>2.435484</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>4</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.018014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>1.02425</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>52</td>\n",
       "      <td>170</td>\n",
       "      <td>1717</td>\n",
       "      <td>...</td>\n",
       "      <td>33.410256</td>\n",
       "      <td>2.179487</td>\n",
       "      <td>273.487179</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>2.589744</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1.056456</td>\n",
       "      <td>0.065234</td>\n",
       "      <td>0.017268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           name  Car Rating  tier  Year   G  GS  Win   TD   Cmp  ...  \\\n",
       "0      0  Aaron Rodgers     1.02425     1  2008  16  16    6   28   341  ...   \n",
       "1      0  Aaron Rodgers     1.02425     1  2009  32  32   17   58   691  ...   \n",
       "2      0  Aaron Rodgers     1.02425     1  2010  47  47   27   86  1003  ...   \n",
       "3      0  Aaron Rodgers     1.02425     1  2011  62  62   41  131  1346  ...   \n",
       "4      0  Aaron Rodgers     1.02425     1  2012  78  78   52  170  1717  ...   \n",
       "\n",
       "      Att/gm     TD/gm  Pass_Yds/gm    Int/gm     Sk/gm  Career W %  Yrs Xp  \\\n",
       "0  33.500000  1.750000   252.375000  0.812500  2.125000    0.375000       1   \n",
       "1  33.656250  1.812500   264.750000  0.625000  2.625000    0.531250       2   \n",
       "2  33.021277  1.829787   263.702128  0.659574  2.446809    0.574468       3   \n",
       "3  33.129032  2.112903   274.790323  0.596774  2.435484    0.661290       4   \n",
       "4  33.410256  2.179487   273.487179  0.576923  2.589744    0.666667       5   \n",
       "\n",
       "   YTD_Rating       TD%      Int%  \n",
       "0    0.937966  0.052239  0.024254  \n",
       "1    0.985395  0.053853  0.018570  \n",
       "2    0.993610  0.055412  0.019974  \n",
       "3    1.050065  0.063778  0.018014  \n",
       "4    1.056456  0.065234  0.017268  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_df['TD%'] = car_avg_df.apply(lambda x: x['TD'] / x['Att'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_df['Int%'] = car_avg_df.apply(lambda x: x['Int'] / x['Att'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_ratings = car_avg_df.groupby('name', as_index=False).agg({'YTD_Rating':'mean'})\n",
    "career_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(career_ratings['YTD_Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used qcut to classify QBs into 3 different tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_ratings['tier'] = pd.qcut(career_ratings['YTD_Rating'], 3, labels = [3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_ratings['tier'] = career_ratings['tier'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = career_ratings.merge(car_avg_df, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.rename({'YTD_Rating_x':'Car Rating', 'YTD_Rating_y':'YTD_Rating'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few key 2018 QBs got hurt. Stashing their data here before I drop all NaNs\n",
    "benched_injured_df = data_stats[(data_stats['FY_TD'].isna()) &\n",
    "          (data_stats['Year'] == 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_stats = ['Year','FY_TD','G','Career W %','Cmp/gm',\n",
    "                 'Att/gm','TD/gm','TD%','Int%','Pass_Yds/gm','Int/gm',\n",
    "                 'Sk/gm', 'Yrs Xp', 'tier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_graph_df = data_stats[car_avg_stats]\n",
    "car_avg_graph_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QB tier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_graph_df = car_avg_graph_df[car_avg_graph_df['tier'] == 1]\n",
    "tier2_graph_df =car_avg_graph_df[car_avg_graph_df['tier'] == 2]\n",
    "tier3_graph_df =car_avg_graph_df[car_avg_graph_df['tier'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_graph_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier2_graph_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier3_graph_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "ax1 = sns.heatmap(tier1_graph_df.corr(), cmap='seismic', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "ax2 = sns.heatmap(tier2_graph_df.corr(), cmap='seismic', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "ax3 = sns.heatmap(tier3_graph_df.corr(), cmap='seismic', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(car_avg_graph_df, height=1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set thinking\n",
    "2018 is the test set to compare to 2019 actual performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_avg_graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_2018 = data_stats[data_stats['Year'] == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = car_avg_graph_df[car_avg_graph_df['Year'] < 2018].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_deviation_feature(X, feature, category):\n",
    "    \n",
    "    # temp groupby object\n",
    "    category_gb = X.groupby(category)[feature]\n",
    "    \n",
    "    # create columns of category means and standard deviations\n",
    "    category_mean = category_gb.transform(lambda x: x.mean())\n",
    "    category_std = category_gb.transform(lambda x: x.std())\n",
    "    \n",
    "    # compute stds from category mean for each feature value,\n",
    "    # add to X as new feature\n",
    "    deviation_feature = (X[feature] - category_mean) / category_std \n",
    "    X[feature + '_Dev_' + category] = deviation_feature\n",
    "    X[feature + '_Dev_' + category].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_deviation_feature(train_val_df, 'TD/gm', 'tier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with non-test set\n",
    "\n",
    "## Create model in sm and perform LR Assumption / residual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-transformed FY TD\n",
    "X = train_val_df.drop(['FY_TD'], axis=1)\n",
    "y = np.log(train_val_df['FY_TD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note to self, all y has been transformed at this point (including for test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assumption_test_df = train_val_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_model_for_residuals(df, X, y):\n",
    "    x_for_sm = sm.add_constant(X)\n",
    "    sm_linear_all = sm.OLS(y, X).fit()\n",
    "    \n",
    "    df['predict']=sm_linear_all.predict(X)\n",
    "    df['resid']= y-df['predict']\n",
    "    with sns.axes_style('white'):\n",
    "        plot = df.plot(\n",
    "            kind='scatter', x='predict', y='resid', alpha=0.5, figsize=(10,6))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_residuals = stats_model_for_residuals(train_val_df, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "stats.probplot(df_with_residuals['resid'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals appear to be slightly left skewed with minor fluctuations in the error variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for log transformed only\n",
    "def MSE_calc(y_val, val_pred):\n",
    "    return sum((np.exp(y_val) - np.exp(val_pred))**2)/len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_CV(X, y):\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "    cv_lm_r2 = []\n",
    "    cv_ridge_r2 = []\n",
    "    cv_lm_MSE = []\n",
    "    \n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind]\n",
    "        \n",
    "        # Linear model\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        cv_lm_r2.append(lr_model.score(X_val, y_val))\n",
    "        val_pred = lr_model.predict(X_val)\n",
    "        MSE_man = MSE_calc(y_val, val_pred)\n",
    "        cv_lm_MSE.append(MSE_man)\n",
    "\n",
    "        # Ridge model\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        lm_ridge = Ridge(alpha=.1)\n",
    "        lm_ridge.fit(X_train_scaled, y_train)\n",
    "        cv_ridge_r2.append(lm_ridge.score(X_val_scaled, y_val))\n",
    "    \n",
    "    print(f'R^2 LM reg: {cv_lm_r2}')\n",
    "    print(f'LM reg mean cv R^2: {np.mean(cv_lm_r2):.3f} +- {np.std(cv_lm_r2):.3f}')\n",
    "    print(f'MSE: {cv_lm_MSE}')\n",
    "    print(f'MSE simple mean: {np.mean(cv_lm_MSE)}\\n')\n",
    "\n",
    "    print(f'R^2 Ridge: {cv_ridge_r2}')\n",
    "    print(f'LM ridge mean cv R^2: {np.mean(cv_ridge_r2):.3f} +- {np.std(cv_ridge_r2):.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_CV(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial regression\n",
    "\n",
    "def poly_add(X,y,alpha=1):\n",
    "    cv_poly_r2 = []\n",
    "    cv_poly_MSE = []\n",
    "    cv_ridge_r2 = []\n",
    "    cv_ridge_MSE = []\n",
    "    cv_LASSO_r2 = []\n",
    "    cv_LASSO_MSE = []\n",
    "    \n",
    "    # Polynomial factors\n",
    "    \n",
    "    X['PY/G^2'] = X['Pass_Yds/gm'] ** 3 + X['Pass_Yds/gm'] ** 2\n",
    "    X['Cmp/G^2'] = X['Cmp/gm'] ** 3 + X['Cmp/gm'] ** 2\n",
    "    X['TD/gm^2'] = X['TD/gm'] ** 3 + X['TD/gm'] ** 2\n",
    "    X['Yrs Xp^2'] = X['Yrs Xp']**2\n",
    "    \n",
    "    # Add interaction terms\n",
    "    X['TD%_/_Int%'] = X['TD%'] / X['Int%']\n",
    "    \n",
    "    \n",
    "    X, y = np.array(X), np.array(y)   \n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "    for train_ind, val_ind in kf.split(X,y):\n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind]\n",
    "        \n",
    "        # Feature engineered model\n",
    "        poly_model = LinearRegression()\n",
    "        poly_model.fit(X_train, y_train)\n",
    "        cv_poly_r2.append(poly_model.score(X_val, y_val))\n",
    "        val_pred = poly_model.predict(X_val)\n",
    "        MSE_man = MSE_calc(y_val, val_pred)\n",
    "        cv_poly_MSE.append(MSE_man)\n",
    "        \n",
    "        #### Regularization Section ####\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # Ridge\n",
    "#         lm_ridge = Ridge(alpha=alpha)\n",
    "#         lm_ridge.fit(X_train_scaled, y_train)\n",
    "#         cv_ridge_r2.append(lm_ridge.score(X_val_scaled, y_val))\n",
    "#         val_pred = lm_ridge.predict(X_val_scaled)\n",
    "#         MSE_man = MSE_calc(y_val, val_pred)\n",
    "#         cv_ridge_MSE.append(MSE_man)\n",
    "        \n",
    "        # LASSO\n",
    "        lasso_model = Lasso(alpha=alpha)\n",
    "        lasso_model.fit(X_train_scaled, y_train)\n",
    "        cv_LASSO_r2.append(lasso_model.score(X_val_scaled, y_val))\n",
    "        val_pred = lasso_model.predict(X_val_scaled)\n",
    "        MSE_man = MSE_calc(y_val, val_pred)\n",
    "        cv_LASSO_MSE.append(MSE_man)\n",
    "        \n",
    "    print(f'R^2 Poly: {cv_poly_r2}')\n",
    "    print(f'Poly mean cv R^2: {np.mean(cv_poly_r2):.3f} +- {np.std(cv_poly_r2):.3f}')\n",
    "    print(f'Poly MSE: {cv_poly_MSE}')\n",
    "    print(f'Poly MSE: {np.mean(cv_poly_MSE):.3f} +- {np.std(cv_poly_MSE):.3f}\\n')\n",
    " \n",
    "#     print(f'R^2 Ridge: {cv_ridge_r2}')\n",
    "#     print(f'Poly ridge mean cv R^2: {np.mean(cv_ridge_r2):.3f} +- {np.std(cv_ridge_r2):.3f}')\n",
    "#     print(f'Poly ridge MSE: {cv_ridge_MSE}')\n",
    "#     print(f'Poly MSE: {np.mean(cv_ridge_MSE):.3f} +- {np.std(cv_ridge_MSE):.3f}\\n')\n",
    "\n",
    "    print(f'R^2 LASSO: {cv_LASSO_r2}')\n",
    "    print(f'Poly LASSO mean cv R^2: {np.mean(cv_LASSO_r2):.3f} +- {np.std(cv_LASSO_r2):.3f}')\n",
    "    print(f'Poly LASSO MSE: {cv_LASSO_MSE}')\n",
    "    print(f'Poly MSE: {np.mean(cv_LASSO_MSE):.3f} +- {np.std(cv_LASSO_MSE):.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_add(X,y,.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_with_CV(X,y):\n",
    "    lasso_model_score = []    \n",
    "    # Polynomial factors\n",
    "    \n",
    "    X['PY/G^2'] = X['Pass_Yds/gm'] ** 3 + X['Pass_Yds/gm'] ** 2\n",
    "    X['Cmp/G^2'] = X['Cmp/gm'] ** 3 + X['Cmp/gm'] ** 2\n",
    "    X['TD/gm^2'] = X['TD/gm'] ** 3 + X['TD/gm'] ** 2\n",
    "    X['Yrs Xp^2'] = X['Yrs Xp']**2\n",
    "    \n",
    "    # Add interaction terms\n",
    "    X['TD%_/_Int%'] = X['TD%'] / X['Int%']\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train.values)\n",
    "    \n",
    "    X_tr_scaled = scaler.transform(X_train.values)\n",
    "    X_val_scaled = scaler.transform(X_val.values)\n",
    "    \n",
    "    alphavec = 10**np.linspace(-2,2,200)\n",
    "    lasso_model = LassoCV(alphas=alphavec, cv=4)\n",
    "    lasso_model.fit(X_tr_scaled, y_train)\n",
    "    lasso_model_score.append(lasso_model.score(X_val_scaled, y_val))\n",
    "    val_pred = lasso_model.predict(X_val_scaled)\n",
    "    print(lasso_model.alpha_)\n",
    "    print(MSE_calc(y_val, val_pred))\n",
    "    print(lasso_model_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_with_CV(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_with_CV(X,y):\n",
    "    Ridge_model_score = []  \n",
    "    # Polynomial factors\n",
    "    X['PY/G^2'] = X['Pass_Yds/gm'] ** 3 + X['Pass_Yds/gm'] ** 2\n",
    "    X['Cmp/G^2'] = X['Cmp/gm'] ** 3 + X['Cmp/gm'] ** 2\n",
    "    X['TD/gm^2'] = X['TD/gm'] ** 3 + X['TD/gm'] ** 2\n",
    "    \n",
    "    # Add interaction terms\n",
    "    X['TD%_/_Int%'] = X['TD%'] / X['Int%']\n",
    "    \n",
    "    # split, scale, transform\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train.values)\n",
    "    X_tr_scaled = scaler.transform(X_train.values)\n",
    "    X_val_scaled = scaler.transform(X_val.values)\n",
    "    \n",
    "    alphavec = 10**np.linspace(-2,2,200)\n",
    "    ridge_model = RidgeCV(alphas=alphavec, cv=4)\n",
    "    ridge_model.fit(X_tr_scaled, y_train)\n",
    "    val_pred = ridge_model.predict(X_val_scaled)\n",
    "    Ridge_model_score.append(ridge_model.score(X_val_scaled, y_val))\n",
    "    print(ridge_model.alpha_)\n",
    "    print(MSE_calc(y_val, val_pred))\n",
    "    print(ridge_model.score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_with_CV(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on validation (2017) to get a feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = data_stats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_deviation_feature(test_input, 'TD/gm', 'tier' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_train, y, X_test, alpha=0.01):\n",
    "    \n",
    "    X_train['PY/G^2'] = X_train['Pass_Yds/gm'] ** 3 + X_train['Pass_Yds/gm'] ** 2\n",
    "    X_train['Cmp/G^2'] = X_train['Cmp/gm'] ** 3 + X_train['Cmp/gm'] ** 2\n",
    "    X_train['TD/gm^2'] = X_train['TD/gm'] ** 3 + X_train['TD/gm'] ** 2\n",
    "    X_train['Yrs Xp^2'] = X_train['Yrs Xp']**2    \n",
    "    X_train['TD%_/_Int%'] = X_train['TD%'] / X_train['Int%']\n",
    "\n",
    "    X_test['PY/G^2'] = X_test['Pass_Yds/gm'] ** 3 + X_test['Pass_Yds/gm'] ** 2\n",
    "    X_test['Cmp/G^2'] = X_test['Cmp/gm'] ** 3 + X_test['Cmp/gm'] ** 2\n",
    "    X_test['TD/gm^2'] = X_test['TD/gm'] ** 3 + X_test['TD/gm'] ** 2\n",
    "    X_test['Yrs Xp^2'] = X_test['Yrs Xp']**2\n",
    "    X_test['TD%_/_Int%'] = X_test['TD%'] / X_test['Int%']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "#     poly_model = LinearRegression()\n",
    "#     poly_model.fit(X_train, y)\n",
    "#     predictions = poly_model.predict(X_test)\n",
    "    \n",
    "    # LASSO\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_tr_scaled, y)\n",
    "    ln_predictions = lasso_model.predict(X_test_scaled)\n",
    "    coefs = dict(zip(X_test.columns,lasso_model.coef_))\n",
    "    for key, val in coefs.items():\n",
    "        print(key,val)\n",
    "    return ln_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = ['name','Year', 'FY_TD', 'G', 'Career W %', 'Cmp/gm', 'Att/gm', 'TD/gm', 'TD%',\n",
    "       'Int%', 'Pass_Yds/gm', 'Int/gm', 'Sk/gm', 'Yrs Xp', 'tier', 'TD/gm_Dev_tier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to filter features\n",
    "test_input = test_input[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input[test_input['Year'] == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = test_model(X,y,test_input.drop(['name','FY_TD'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict=test_input[['name','FY_TD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict['Pred'] = np.exp(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict['residual'] = abs(test_predict['FY_TD'] - test_predict['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test_predict['residual']) / len(test_predict['residual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the test data and running predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_set_2018 = test_df_2018.append(benched_injured_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_deviation_feature(qb_set_2018, 'TD/gm', 'tier' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_set_2018 = qb_set_2018[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(X_train, y, X_test, alpha=0.01):\n",
    "    \n",
    "    X_train['PY/G^2'] = X_train['Pass_Yds/gm'] ** 3 + X_train['Pass_Yds/gm'] ** 2\n",
    "    X_train['Cmp/G^2'] = X_train['Cmp/gm'] ** 3 + X_train['Cmp/gm'] ** 2\n",
    "    X_train['TD/gm^2'] = X_train['TD/gm'] ** 3 + X_train['TD/gm'] ** 2\n",
    "    X_train['Yrs Xp^2'] = X_train['Yrs Xp']**2    \n",
    "    X_train['TD%_/_Int%'] = X_train['TD%'] / X_train['Int%']\n",
    "\n",
    "    X_test['PY/G^2'] = X_test['Pass_Yds/gm'] ** 3 + X_test['Pass_Yds/gm'] ** 2\n",
    "    X_test['Cmp/G^2'] = X_test['Cmp/gm'] ** 3 + X_test['Cmp/gm'] ** 2\n",
    "    X_test['TD/gm^2'] = X_test['TD/gm'] ** 3 + X_test['TD/gm'] ** 2\n",
    "    X_test['Yrs Xp^2'] = X_test['Yrs Xp']**2\n",
    "    X_test['TD%_/_Int%'] = X_test['TD%'] / X_test['Int%']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_tr_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # LASSO\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_tr_scaled, y)\n",
    "    ln_predictions = lasso_model.predict(X_test_scaled)\n",
    "    print(lasso_model.coef_)\n",
    "    \n",
    "    return ln_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = final_model(X,y,qb_set_2018.drop(['name','FY_TD'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = qb_set_2018[['name','FY_TD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Pred'] = np.round_(np.exp(test_results), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Residual'] = results_df['Pred'] - results_df['FY_TD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['% var'] = (results_df['Residual'] / results_df['FY_TD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(by='FY_TD', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.scatter(results_df['FY_TD'], results_df['Pred'])\n",
    "plt.title('Actual vs. Projected Passing TD', fontsize=40)\n",
    "plt.xlabel('Actual', fontsize=14)\n",
    "plt.ylabel('Projected', fontsize=14)\n",
    "plt.savefig('result_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Residual'].apply(lambda x: x**2).sum() / len(results_df['Residual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And for my 2019 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_df_raw_2019 = pd.read_pickle('2019_data_for_pred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_list_2019 = ['Josh Allen', 'Ryan Fitzpatrick', 'Cam Newton', 'Sam Darnold', 'Lamar Jackson',\n",
    "#                    'Baker Mayfield', 'Ben Roethlisberger', 'Deshaun Watson', 'Philip Rivers', 'Ryan Tannehill',\n",
    "#                    'Patrick Mahomes', 'Derek Carr', 'Tyrod Taylor', 'Dak Prescott', 'Carson Wentz', 'Dwayne Haskins',\n",
    "#                    'Mitchell Trubisky', 'Matthew Stafford', 'Aaron Rodgers', 'Kirk Cousins', 'Matt Ryan', 'Drew Brees',\n",
    "#                    'Tom Brady', 'Kyler Murray', 'Jared Goff', 'Jimmy Garoppolo', 'Russell Wilson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_df_raw_2019['TD%'] = qb_df_raw_2019.apply(lambda x: x['TD'] / x['Att'], axis=1)\n",
    "qb_df_raw_2019['Int%'] = qb_df_raw_2019.apply(lambda x: x['Int'] / x['Att'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_2019_data = career_ratings.merge(qb_df_raw_2019, on='name', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually filling in data for Jimmy G and Lamar\n",
    "qb_2019_data['YTD_Rating'] = qb_2019_data.apply(calc_passer_rating, axis=1)\n",
    "qb_2019_data.loc[21,'tier'] = 1\n",
    "qb_2019_data.loc[22,'tier'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_deviation_feature(qb_2019_data, 'TD/gm', 'tier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_set_2019 = qb_2019_data[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_set_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_set_2019.drop(['name','FY_TD'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_2019 = final_model(X,y,qb_set_2019.drop(['name','FY_TD'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2019 = pd.DataFrame(qb_set_2019['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2019['2020 Prediction'] = np.round_(np.exp(predict_2019), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2019.sort_values(by='2020 Prediction',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the results and figure out confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_interval(prediction, y_test, test_predictions, pi=.95):\n",
    "    '''\n",
    "    Get a prediction interval for a linear regression.\n",
    "    \n",
    "    INPUTS: \n",
    "        - Single prediction, \n",
    "        - y_test\n",
    "        - All test set predictions,\n",
    "        - Prediction interval threshold (default = .95) \n",
    "    OUTPUT: \n",
    "        - Prediction interval for single prediction\n",
    "    '''\n",
    "    \n",
    "    #get standard deviation of y_test\n",
    "    sum_errs = np.sum((y_test - test_predictions)**2)\n",
    "    stdev = np.sqrt(1 / (len(y_test) - 2) * sum_errs)\n",
    "#get interval from standard deviation\n",
    "    one_minus_pi = 1 - pi\n",
    "    ppf_lookup = 1 - (one_minus_pi / 2)\n",
    "    z_score = stats.norm.ppf(ppf_lookup)\n",
    "    interval = z_score * stdev\n",
    "#generate prediction interval lower and upper bound\n",
    "    lower, upper = prediction - interval, prediction + interval\n",
    "    return lower, prediction, upper\n",
    "get_prediction_interval(predictions[0], y_test, predictions)\n",
    "OUTPUT: (19.24072024369257, 28.996723619824934, 38.752726995957296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_test(X_train, y, X_test, alpha=0.01):\n",
    "    \n",
    "    X_train['PY/G^2'] = X_train['Pass_Yds/gm'] ** 3 + X_train['Pass_Yds/gm'] ** 2\n",
    "    X_train['Cmp/G^2'] = X_train['Cmp/gm'] ** 3 + X_train['Cmp/gm'] ** 2\n",
    "    X_train['TD/gm^2'] = X_train['TD/gm'] ** 3 + X_train['TD/gm'] ** 2\n",
    "    X_train['TD%_/_Int%'] = X_train['TD%'] / X_train['Int%']\n",
    "\n",
    "    X_test['PY/G^2'] = X_test['Pass_Yds/gm'] ** 3 + X_test['Pass_Yds/gm'] ** 2\n",
    "    X_test['Cmp/G^2'] = X_test['Cmp/gm'] ** 3 + X_test['Cmp/gm'] ** 2\n",
    "    X_test['TD/gm^2'] = X_test['TD/gm'] ** 3 + X_test['TD/gm'] ** 2\n",
    "    X_test['TD%_/_Int%'] = X_test['TD%'] / X_test['Int%']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "    # LASSO\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_scaled, y)\n",
    "    predictions = lasso_model.predict(X_test_scaled)\n",
    "    print(lasso_model.coef_)\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
